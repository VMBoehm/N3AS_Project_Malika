{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of First Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMBoehm/N3AS_Project_Malika/blob/main/9_Copy_of_Copy_of_Copy_of_First_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RG7EeHGKzq7D"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets as datasets\n",
        "from sklearn import model_selection as ms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random_seed = 1534"
      ],
      "metadata": {
        "id": "VinrRZc1z9mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK: Play with different class_sep parameters, how does the model accuracy degrade/improve?\n",
        "#dataset = datasets.make_classification(n_samples=1000, n_features=4, random_state=random_seed, class_sep= 3)\n",
        "## n_features = 5 does something weird, We talked about class_sep last monday."
      ],
      "metadata": {
        "id": "uE088GgTzwbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#features, labels = dataset\n",
        "#print(features.shape)"
      ],
      "metadata": {
        "id": "MqtNViA20HMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.scatter(features[:,0],features[:,1], c=labels)\n",
        "#plt.show()\n",
        "#plt.scatter(features[:,2],features[:,3], c=labels)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "qyHr8Kdt0QeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test, y_train, y_test = ms.train_test_split(features,labels, test_size = 0.2)"
      ],
      "metadata": {
        "id": "Pl1IZgAj1RPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('X_train:',np.shape(X_train))\n",
        "#print('y_train:',np.shape(y_train))\n",
        "#print('X_test:',np.shape(X_test))\n",
        "#print('y_test:',np.shape(y_test))"
      ],
      "metadata": {
        "id": "o-gCwy5G1u3u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "fEksAjz52GJN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10 \n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('X_train:',np.shape(X_train))\n",
        "print('y_train:',np.shape(y_train))\n",
        "print('X_test:',np.shape(X_test))\n",
        "print('y_test:',np.shape(y_test))"
      ],
      "metadata": {
        "id": "MSkQrdJZ2UCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1b5533-110a-473e-b1b0-7864c1540be6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (60000, 28, 28)\n",
            "y_train: (60000, 10)\n",
            "X_test: (10000, 28, 28)\n",
            "y_test: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "basic_model = Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "basic_model.summary()\n",
        "# Adding layers to the model\n",
        "# First layers: 16 neurons/perceptrons that takes the input and uses Leaky ReLU activation function.\n",
        "\n",
        "#basic_model.add(Dense(units = 4 , activation = 'LeakyReLU', input_shape = (4,))) \n",
        "# Second layer: 1 neuron/perceptron that takes the input from the 1st layers and gives output as 0 or 1.Activation used is 'Hard Sigmoid'\n",
        "\n",
        "# TASK: Can you change the output to be probabilistic (probability for each class) by using 'softmax' as an activation function?\n",
        "#basic_model.add(Dense(1, activation = 'hard_sigmoid'))\n",
        "### This is what I added. I think this is right.\n",
        "#basic_model.add(Dense(2, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "9KPL-EQ12joy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6de8ed-42c1-46df-a7c1-a4272e5ba80f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK optional): How does the Adam optimizer work? \n",
        "# from googling I have learned that the adam Optimizer is a Stochastic optimization. Which means its does graident optmaztion. I am acutally not really sure how it works\n",
        "## I found this paper about it https://arxiv.org/pdf/1412.6980.pdf but its a little hard to understand.\n",
        "## I know that basically it find how to get down hill the fastest\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "#TASK: What is binary cross entropy? What does it measure?\n",
        "basic_model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "## the Binary cross entropy is ued for our loss paramter which calculates the degree of errror. A neural network measures doesn't measure \n",
        "# acurracy but instead loss. This is than used to measure accuracy. Binary_crossentropy is used when you have a binary system like cats or dogs or 1 and 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G4sTxfwv2wjV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK: add validation data (https://keras.io/api/models/model_training_apis/)\n",
        "#basic_model.fit(X_train, y_train, epochs=50, validation_data= (X_test, y_test))\n",
        "basic_model.fit(X_train, y_train, batch_size=128, epochs=50, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOFZ5cM02_5M",
        "outputId": "6ebb5aa2-f24b-4dfc-8efa-7ebdae9f110c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "422/422 [==============================] - 41s 95ms/step - loss: 1.0554 - accuracy: 0.8536 - val_loss: 0.1053 - val_accuracy: 0.9698\n",
            "Epoch 2/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2550 - accuracy: 0.9218 - val_loss: 0.1036 - val_accuracy: 0.9683\n",
            "Epoch 3/50\n",
            "422/422 [==============================] - 41s 96ms/step - loss: 0.2522 - accuracy: 0.9243 - val_loss: 0.1004 - val_accuracy: 0.9690\n",
            "Epoch 4/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2578 - accuracy: 0.9236 - val_loss: 0.0791 - val_accuracy: 0.9768\n",
            "Epoch 5/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2385 - accuracy: 0.9286 - val_loss: 0.1180 - val_accuracy: 0.9655\n",
            "Epoch 6/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2674 - accuracy: 0.9234 - val_loss: 0.1179 - val_accuracy: 0.9653\n",
            "Epoch 7/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2442 - accuracy: 0.9274 - val_loss: 0.1115 - val_accuracy: 0.9673\n",
            "Epoch 8/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2712 - accuracy: 0.9216 - val_loss: 0.0824 - val_accuracy: 0.9772\n",
            "Epoch 9/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2296 - accuracy: 0.9335 - val_loss: 0.0900 - val_accuracy: 0.9725\n",
            "Epoch 10/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2325 - accuracy: 0.9331 - val_loss: 0.1049 - val_accuracy: 0.9712\n",
            "Epoch 11/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2336 - accuracy: 0.9330 - val_loss: 0.0897 - val_accuracy: 0.9752\n",
            "Epoch 12/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2213 - accuracy: 0.9375 - val_loss: 0.0847 - val_accuracy: 0.9757\n",
            "Epoch 13/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2380 - accuracy: 0.9330 - val_loss: 0.1081 - val_accuracy: 0.9697\n",
            "Epoch 14/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2479 - accuracy: 0.9301 - val_loss: 0.0966 - val_accuracy: 0.9710\n",
            "Epoch 15/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2454 - accuracy: 0.9303 - val_loss: 0.1116 - val_accuracy: 0.9677\n",
            "Epoch 16/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2568 - accuracy: 0.9273 - val_loss: 0.1000 - val_accuracy: 0.9747\n",
            "Epoch 17/50\n",
            "422/422 [==============================] - 41s 96ms/step - loss: 0.2954 - accuracy: 0.9189 - val_loss: 0.1203 - val_accuracy: 0.9673\n",
            "Epoch 18/50\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.2404 - accuracy: 0.9311 - val_loss: 0.1466 - val_accuracy: 0.9588\n",
            "Epoch 19/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2522 - accuracy: 0.9266 - val_loss: 0.1170 - val_accuracy: 0.9685\n",
            "Epoch 20/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2622 - accuracy: 0.9241 - val_loss: 0.1072 - val_accuracy: 0.9690\n",
            "Epoch 21/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2637 - accuracy: 0.9254 - val_loss: 0.1055 - val_accuracy: 0.9700\n",
            "Epoch 22/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2651 - accuracy: 0.9243 - val_loss: 0.1099 - val_accuracy: 0.9673\n",
            "Epoch 23/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2577 - accuracy: 0.9256 - val_loss: 0.0981 - val_accuracy: 0.9732\n",
            "Epoch 24/50\n",
            "422/422 [==============================] - 41s 96ms/step - loss: 0.3000 - accuracy: 0.9140 - val_loss: 0.1228 - val_accuracy: 0.9647\n",
            "Epoch 25/50\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.2654 - accuracy: 0.9231 - val_loss: 0.1295 - val_accuracy: 0.9612\n",
            "Epoch 26/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2611 - accuracy: 0.9254 - val_loss: 0.1017 - val_accuracy: 0.9687\n",
            "Epoch 27/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2751 - accuracy: 0.9206 - val_loss: 0.1215 - val_accuracy: 0.9650\n",
            "Epoch 28/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2860 - accuracy: 0.9192 - val_loss: 0.1171 - val_accuracy: 0.9645\n",
            "Epoch 29/50\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.2750 - accuracy: 0.9190 - val_loss: 0.1172 - val_accuracy: 0.9673\n",
            "Epoch 30/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2975 - accuracy: 0.9162 - val_loss: 0.1206 - val_accuracy: 0.9642\n",
            "Epoch 31/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2846 - accuracy: 0.9166 - val_loss: 0.1222 - val_accuracy: 0.9645\n",
            "Epoch 32/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.3002 - accuracy: 0.9148 - val_loss: 0.1600 - val_accuracy: 0.9522\n",
            "Epoch 33/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2732 - accuracy: 0.9191 - val_loss: 0.1150 - val_accuracy: 0.9635\n",
            "Epoch 34/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2666 - accuracy: 0.9221 - val_loss: 0.1054 - val_accuracy: 0.9687\n",
            "Epoch 35/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2601 - accuracy: 0.9229 - val_loss: 0.1256 - val_accuracy: 0.9670\n",
            "Epoch 36/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2714 - accuracy: 0.9211 - val_loss: 0.1073 - val_accuracy: 0.9667\n",
            "Epoch 37/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2781 - accuracy: 0.9192 - val_loss: 0.1199 - val_accuracy: 0.9640\n",
            "Epoch 38/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2684 - accuracy: 0.9214 - val_loss: 0.1336 - val_accuracy: 0.9622\n",
            "Epoch 39/50\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.2720 - accuracy: 0.9191 - val_loss: 0.1141 - val_accuracy: 0.9693\n",
            "Epoch 40/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.3074 - accuracy: 0.9110 - val_loss: 0.1367 - val_accuracy: 0.9602\n",
            "Epoch 41/50\n",
            "422/422 [==============================] - 40s 96ms/step - loss: 0.2868 - accuracy: 0.9155 - val_loss: 0.1488 - val_accuracy: 0.9630\n",
            "Epoch 42/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2894 - accuracy: 0.9159 - val_loss: 0.1329 - val_accuracy: 0.9612\n",
            "Epoch 43/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2827 - accuracy: 0.9165 - val_loss: 0.1406 - val_accuracy: 0.9615\n",
            "Epoch 44/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2806 - accuracy: 0.9178 - val_loss: 0.1402 - val_accuracy: 0.9567\n",
            "Epoch 45/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2901 - accuracy: 0.9147 - val_loss: 0.1272 - val_accuracy: 0.9610\n",
            "Epoch 46/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.2883 - accuracy: 0.9146 - val_loss: 0.1349 - val_accuracy: 0.9588\n",
            "Epoch 47/50\n",
            "422/422 [==============================] - 41s 96ms/step - loss: 0.2955 - accuracy: 0.9117 - val_loss: 0.1434 - val_accuracy: 0.9583\n",
            "Epoch 48/50\n",
            "422/422 [==============================] - 41s 96ms/step - loss: 0.2884 - accuracy: 0.9142 - val_loss: 0.1320 - val_accuracy: 0.9603\n",
            "Epoch 49/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.3008 - accuracy: 0.9114 - val_loss: 0.1158 - val_accuracy: 0.9640\n",
            "Epoch 50/50\n",
            "422/422 [==============================] - 40s 95ms/step - loss: 0.3113 - accuracy: 0.9087 - val_loss: 0.1232 - val_accuracy: 0.9605\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2fdc5d1c10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_p=basic_model.predict(X_train)"
      ],
      "metadata": {
        "id": "q05zczrRnHlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_and_metrics = basic_model.evaluate(X_test, y_test)\n",
        "print('Loss = ',loss_and_metrics[0])\n",
        "print('Accuracy = ',loss_and_metrics[1])\n"
      ],
      "metadata": {
        "id": "f9z3BuKo3ZoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69be68cb-830e-4b53-a07d-91b02c3ccc59"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1510 - accuracy: 0.9544\n",
            "Loss =  0.1510339230298996\n",
            "Accuracy =  0.9544000029563904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calulating accuracy from scartch\n",
        "## so this is a binary acuraccy calcuation\n",
        "from sklearn.preprocessing import normalize\n",
        "y_test = y_test[:, 0]\n",
        "probs = basic_model.predict(X_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "y_pred = (preds >= .5).astype('int')\n",
        "print(np.shape(y_pred))\n",
        "#y_pred = y_pred[:, 0]\n",
        "y_pred_train = (X_train >= .5).astype('int')\n",
        "y_pred_train = y_pred_train[:, 0]\n",
        "\n",
        "def compute_tp_tn_fn_fp(act, pred):\n",
        "\n",
        "\ttp = sum((act == 1) & (pred == 1))\n",
        "\ttn = sum((act == 0) & (pred == 0))\n",
        "\tfn = sum((act == 1) & (pred == 0))\n",
        "\tfp = sum((act == 0) & (pred == 1))\n",
        "\treturn tp, tn, fp, fn\n",
        "\n",
        "# tp_t, tn_t, fp_t, fn_t = compute_tp_tn_fn_fp(y_train,y_pred)\n",
        "\n",
        "tp_k, tn_k, fp_k, fn_k = compute_tp_tn_fn_fp(y_test,y_pred )\n",
        "\n",
        "def compute_accuracy(tp, tn, fn, fp):\n",
        "  return((tp + tn) * 100)/ float( tp + tn + fn + fp)\n",
        "  \n",
        "#print(\"test acuuracy\",compute_accuracy(tp_e, tn_e, fn_e, fp_e))\n",
        "\n",
        "#print(\"train accuracy\",compute_accuracy(tp_t, tn_t, fp_t, fn_t))\n",
        "\n",
        "print(\"test acuuracy\",compute_accuracy(tp_k, tn_k, fn_k, fp_k))\n",
        "print(\"train accuracy\",compute_accuracy(tp_t, tn_t, fp_t, fn_t))\n"
      ],
      "metadata": {
        "id": "MZLeDWq-yXge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "fe62896c-7108-4ed6-ae90-82dd52e4e84c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-35a381698f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## so this is a binary acuraccy calcuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "probs = basic_model.predict(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, probs)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([-0.1, 1])\n",
        "plt.ylim([0, 1.1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_QhpnmjBAdDw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "9125b2cb-59a6-4b28-b0b4-471a18767d49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c79a10ad1feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \"\"\"\n\u001b[1;32m    962\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
          ]
        }
      ]
    }
  ]
}