{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180db82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##In this kernel I am just importing all of the torch vision things\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import io\n",
    "from torchvision import models\n",
    "from torchvision import ops\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf520f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## more stuff to import just incase \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebb0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading in the data\n",
    "DATA_DIR= '/Users/malikagolshan/Desktop/z1'\n",
    "image_size = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root= DATA_DIR, transform=TRANSFORM_IMG)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_data = torchvision.datasets.ImageFolder(root=DATA_DIR, transform=TRANSFORM_IMG)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e169befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This all Adrains Code\n",
    "class model_p(nn.Module):\n",
    "    def __init__(self, hidden= 8, dr= 0.1):\n",
    "        super(model_p, self).__init__()\n",
    "        \n",
    "        kernel_size = 3  # 4\n",
    "        padding = 1\n",
    "        \n",
    "        # input: 1x512x512 ---------------> output: hiddenx256x256 (the stride of 2 with pad of 1 halves dim)\n",
    "        self.C1 = nn.Conv2d(3,         hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B1 = nn.BatchNorm2d(hidden)\n",
    "        \n",
    "        # input: hiddenx256x256 ----------> output: 2*hiddenx128x128\n",
    "        self.C2 = nn.Conv2d(hidden,   2*hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B2 = nn.BatchNorm2d(2*hidden)\n",
    "        \n",
    "        # input: 2*hiddenx128x128 --------> output: 4*hiddenx64x64\n",
    "        self.C3 = nn.Conv2d(2*hidden, 4*hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B3 = nn.BatchNorm2d(4*hidden)\n",
    "        \n",
    "        # input: 4*hiddenx64x64 --------> output: 8*hiddenx32x32\n",
    "        self.C4 = nn.Conv2d(4*hidden, 8*hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B4 = nn.BatchNorm2d(8*hidden)\n",
    "        \n",
    "        # input: 8*hiddenx32x32 --------> output: 16*hiddenx16x16\n",
    "        self.C5 = nn.Conv2d(8*hidden, 16*hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B5 = nn.BatchNorm2d(16*hidden)\n",
    "        \n",
    "        # input: 16*hiddenx16x16 --------> output: 32*hiddenx8x8\n",
    "        self.C6 = nn.Conv2d(16*hidden, 32*hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B6 = nn.BatchNorm2d(32*hidden)\n",
    "        \n",
    "        # input: 32*hiddenx8x8 ----------> output: 64*hiddenx4x4\n",
    "        self.C7 = nn.Conv2d(32*hidden, 64*hidden, kernel_size=kernel_size, stride=2, padding=padding, bias=True)\n",
    "        self.B7 = nn.BatchNorm2d(64*hidden)\n",
    "        \n",
    "        # input: 64*hiddenx4x4 ----------> output: 50x4x4\n",
    "        self.C8 = nn.Conv2d(64*hidden, 50, kernel_size=kernel_size, stride=1, padding=padding, bias=True)\n",
    "        self.B8 = nn.BatchNorm2d(50)\n",
    "\n",
    "        self.FC1  = nn.Linear(50*4*4, 400)  \n",
    "        self.FC2  = nn.Linear(400,   100)    \n",
    "        self.FC3  = nn.Linear(100,   1)    \n",
    "\n",
    "        self.Dropout   = nn.Dropout(p=dr)\n",
    "        self.ReLU      = nn.ReLU()\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        #self.tanh      = nn.Tanh()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):# or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.LeakyReLU(self.C1(image))\n",
    "        x = self.LeakyReLU(self.B2(self.C2(x)))\n",
    "        x = self.LeakyReLU(self.B3(self.C3(x)))\n",
    "        x = self.LeakyReLU(self.B4(self.C4(x)))\n",
    "        x = self.LeakyReLU(self.B5(self.C5(x)))\n",
    "        x = self.LeakyReLU(self.B6(self.C6(x)))\n",
    "        x = self.LeakyReLU(self.B7(self.C7(x)))\n",
    "        x = self.LeakyReLU(self.B8(self.C8(x)))\n",
    "        x = x.view(image.shape[0],-1)\n",
    "        x = self.LeakyReLU(self.FC1(x))\n",
    "        x = self.LeakyReLU(self.FC2(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = self.FC3(x)\n",
    "        # INCLUDE SIGMOID OUTSIDE OF NEWTORK (torch.nn.BCEWithLogitsLoss is more stable)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "812b5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = model_p() ## just to make it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1dbdf8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x50 and 800x400)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m b_x \u001b[38;5;241m=\u001b[39m Variable(x)   \u001b[38;5;66;03m# batch x (image)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m b_y \u001b[38;5;241m=\u001b[39m Variable(y)   \u001b[38;5;66;03m# batch y (target)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_x\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]          \n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, b_y)   \n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()           \n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36mmodel_p.forward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLeakyReLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB8(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC8(x)))\n\u001b[1;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLeakyReLU(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFC1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     69\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLeakyReLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFC2(x))\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDropout(x)\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x50 and 800x400)"
     ]
    }
   ],
   "source": [
    "model = p1\n",
    "LEARNING_RATE = 0.003\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.BCELoss()\n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "    # Training and Testing\n",
    "for epoch in range(EPOCHS):        \n",
    "    for step, (x, y) in enumerate(train_data_loader):\n",
    "        b_x = Variable(x)   # batch x (image)\n",
    "        b_y = Variable(y)   # batch y (target)\n",
    "        output = model(b_x)[0]          \n",
    "        loss = loss_func(output, b_y)   \n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()                 \n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_x = Variable(test_data_loader)\n",
    "            test_output, last_layer = model(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0],'| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2cfcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
